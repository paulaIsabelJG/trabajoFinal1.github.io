<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chip Soli</title>
    <link rel="stylesheet" href="./css/dispositivo.css">
</head>
<body>
    <header>
        <h1>Chip Soli</h1>
        <nav>
            <ol> 
                <li><a href="#seccion1">¿Qué es el chip Soli?</a></li>
                <li><a href="#seccion2">Características: ventajas y desventajas</a></li>
                <li><a href="#seccion3">Funcionamiento</a></li>
                <li><a href="#importancia">Importancia: más allá de los wereables</a></li>
                <li><a href="#referencias">Más información de interés</a></li>
            </ol>
        </nav>
        <img id="portada" src="./img/portada.jpeg" alt="logo">
        <p>"Your hands are the only interface you need"</p>
    </header>
    <main>
        <section id="seccion1">
            <h2>1.- ¿Qué es el chip Soli?</h2>
            <div id="divseccion1">
                <div id="div1_1">
                    <img src="./img/googleproject.jpeg" alt="Proyecto soli de google">
                    <p> 
                        El Chip Soli nace de un proyecto de Google, presentado en 2015 durante una sesión en su I/O Developer Conference.
                        Desde entonces, la división ATAP (Tecnología y Proyectos Avanzados) de Google ha estado desarrollando esta tecnología, 
                        que se puede utilizar en dispositivos portátiles, teléfonos, automóviles, computadoras y dispositivos de loT. 
                    </p>
                </div>
                <div id="div1_2">
                    <img src="./img/rastreoHumano.jpeg" alt="ejemplo uso Soli Google">
                    <p>
                        Es un chip especialmente diseñado para rastrear movimientos humanos en varias escalas, desde los latidos del corazón 
                        hasta los movimientos de su cuerpo. Para ello utiliza un radar diminuto capaz de seguir el movimiento en tiempo real de la mano humana, 
                        a altas velocidades y con gran precisión. 
                    </p>
                </div>
            </div>
        </section>
        
        <section id="seccion2">
            <h2>2.- Características</h2>
            <div id="div2_1">
                <img id="img2" src="./img/soli1.jpeg" alt="cara 1 del dispositivo soli">
                <img id="img1" src="./img/soli2.jpeg" alt="cara 2 del dispositivo soli">
                <p id="p1">
                    La idea principal del proyecto consistía en crear un radar lo suficientemente pequeño como para caber en un reloj inteligente. 
                    Tras años de investigación, se logró la construcción del chip y de la plataforma Soli, fusionándolos en un solo componente sólido 
                    que se puede integrar en los distintos dispositivos de consumo, pues el último tan solo mide 5,5x6mm capaz de incorporar el sensor 
                    y la matriz de Atenas en un solo dispositivo, lo que permite incluirlo en los dispositivos portátiles más pequeños. 
                </p>
                <img id="img3" src="./img/gestos.jpeg" alt="gestos humanos">
                <p id="p2">
                    Gracias a los radares de Project Soli, se podría controlar un teléfono móvil mediante gestos.  
                    Estos serían controlados por el radar y no por la cámara del teléfono móvil. 
                    Por tanto,  se podría prescindir de la lámina táctil de las pantallas de los teléfonos móviles.
                    Esto la haría más delgada aún y manejable, a la vez que abarataría su fabricación. 
                </p>
                <p id="p3">
                    Además,  cualquier superficie podría convertirse en una superficie activa con este radar, desde la pantalla hasta los marcos, 
                    e incluso la trasera del teléfono. Las posibilidades son enormes
                </p>
            </div>
            <div id="ventajasydesventajas">
                <div id="ventajas">
                    <h3>Ventajas</h3>
                    
                    <ul>
                        <li>
                            <h4>Propósito general</h4>
                            <p>Soli es capaz de detectar materiales, superficies, movimientos</p>
                        </li>
                        <li>
                            <h4>Baja potencia</h4>
                            <p>El bajo consumo de energía permite una detección siemrpe activa</p>
                        </li>
                        <li>
                            <h4>Invisible</h4>
                            <p>Puede ser colocado de forma invisible dentro de las carcasas de los
                                dispositivos porque se propaga a través de los materiales
                            </p>
                        </li>
                        <li>
                            <h4>Privado</h4>
                            <p>Al utilizar un radar que funciona con ondas electromagnéticas, en lugar
                                de una cámara, no captura ninguna imagen visual, lo que proporciona
                                privacidad al usuario.  
                            </p>
                        </li>
                        <li>
                            <h4>No necesita luz</h4>
                            <p>Como identifica los gestos mediante ondas electromagnéticas, y no por cámara de vídeo, 
                                puede ser utilizado en casos de que la luz se vea reducida o incluso en completa oscuridad. 
                            </p>
                        </li>
                    </ul>
                </div>
                <div id="desventajas">
                    <h3>Desventajas</h3>
                    <ul>
                        <li>
                            <h4>Limitaciones</h4>
                            <p>Por un lado, el rango de movimientos capaz de percibir es limitado,
                                 lo que se podría solucionar ampliando y mejorando el número de algoritmos con los que trabaja
                            </p>
                        </li>
                        <li>
                            <h4>Accesibilidad</h4>
                            <p>Puede que algunas personas con discapacidades que afecten al movimiento vean limitada
                                la interacción con los dispositivos que utilizan el chip Soli. Sin embargo, como este 
                                se basa en los movimientos que hacemos para interactuar con el dispositivo, estos usuarios
                                se verían en la misma tesitura en el caso de que no estuviera. 
                            </p>
                        </li>
                        <li>
                            <h4>Coste de adaptación</h4>
                            <p>Los humanos son seres de costumbres a los que les cuesta adaptarse a los cambios radicales, 
                                por los que llevaría un tiempo aceptar el uso del chip Soli y sus gestos. Y más aún para sustituir a las pantallas táctiles </p>
                        </li>
                    </ul>
                    
                </div>
            </div>
            
            <div id="ejemplo">
                <div>
                    <p>
                    Apple Watch tiene la corona digital física que proporciona a los usuarios navegar por la interfaz de WatchOs. Sin embargo, 
                    con el chip Soli, no sería necesaria, pues se podrían mover los dedos para hacer todas las funcionalidades, desde bajar un marcador de volumen para 
                    disminuirlo, presionar un botón para girar, o hasta navegar por las distintas apps
                    </p>
                    <img id="ej2"src="./img/relojconsoli.jpeg" alt="reloj con chip soli">
                   
                </div>
                <img id="ej1"src="./img/applewatch.jpeg" alt="apple watch">
            </div>
            <div id="ejemplo2">
                <p>Además, el Chip Soli no sólo serviría para convertir al ser humano en su propia interfaz, pues esun radar que detecta tanto movimientos pequeños como grandes. 
                     Esto permite que pueda utilizarse con motivos de seguridad o para hacer funciones automáticas como aumentar el volumen de los altavoces cuando se detecte gente de pie, 
                     apagar el televisor cuando no hay nadie al frente por un determinado tiempo, enviarte notificaciones al móvil cuando tu familia o mascotas se hayan despertado (adiós a las webCam), 
                     identificar si en una sala se encuentran ladrones o mascotas y activar o no la alrma (sin necesidad de observarte mediante una cámara), etc.
                </p>
                <div id="imagenesEjemplo">
                    <img src="./img/ejemplo1_1.png" alt="detección de un ladrón mediante ondas electromagnéticas">
                    <img src="./img/bebe.jpeg" alt="bebe vigilado mediante webCam">
                    <img src="./img/fiesta.jpeg" alt="gente bailando en una fiesta con altavoces">
                </div>
            </div>

        </section>
        <section id="seccion3">
            <h2>3.- Funcionamiento</h2>
            <div id="seccion3_1">
                <p id="parrafo1">El chip soli utiliza una tecnología de aprendizaje automático. De esta forma, Soli puede comprender una amplia gama de movimientos posibles. </p>
                <div>
                    <ol>
                        <h3>Pasos</h3>
                        <li>
                            <h4>Emite</h4>
                            <p>
                            Utiliza un radar, que emite ondas electromagnéticas en un haz amplio, donde los objetos, como puede ser una mano humana, 
                            dentro del haz, dispersan esta energía, reflejando una parte hacia la antena del radar
                            </p>
                        
                        </li>
                        <li>
                            <h4>Refleja</h4>
                            <p>
                                Después se captura la información valiosa. Las propiedades de la señal reflejada, como la energía, el tiempo de retardo y el cambio de frecuencia, 
                                capturan la información valiosa sobre las características y comportamientos del objeto, incluyendo el tamaño, forma, orientación, 
                                material, distancia y velocidad
                            </p>
                        </li>
                        <li>
                            <h4>Reconoce</h4>
                            <p>
                                Por último, se encarga de reconocer los movimientos, para lo cual utiliza una tecnología de lenguaje automático. 
                                Al procesar las variaciones temporales y otras características capturadas de la señal, Soli puede distinguir entre movimientos complejos para
                                comprender el tamaño, forma, orientación, material, distancia y velocidad del objeto dentro de su campo. 
                            </p>
                        </li>
                    </ol>
                    <div id="imgseccion3_1">
                        <img src="./img/espectro.jpeg" alt="espectro electromagnético">
                        <img src="./img/pasos.jpeg" alt="funcionamiento chip soli">
                    </div>
                </div>
            </div>
            
            <div id="seccion3_2">
                <h3>Comprensión espacial</h3>
                <div>
                    <div>
                        <p>
                            La interacción de Soli implementa distintas etapas algorítmicas de aumento de la abstracción de datos desde la señal de radar sin procesar 
                            hasta las etiquetas de gestos específicas de la aplicación. Para ello, se utilizan varias etapas de abstracción de señales (desde datos de 
                            radar sin procesar hasta la transformación de señales), una infraestructura de capacitación de aprendizaje automático personalizada para 
                            funciones de abstracción, detección y seguimiento, probabilidades de gestos, y herramientas de interfaz de usuario para interpretar los 
                            controles de gesto. 
                        </p>
                    </div>
                    
                    <div>
                        <img id="flecha" src="./img/flecha.jpeg" alt="flecha hacia abajo">
                        <ol>
                            <li>Gesto</li>
                            <li>Señal sin procesar</li>
                            <li>Tprocransformación de señal Soli</li>
                            <li>Clasificación de gestos</li>
                            <li>Gesto de deslizamiento detectado</li>
                        </ol>
                        <img src="./img/procesosoli.jpeg" alt="proceso de interpretación de señales">
                    </div>
                    <p>
                        Una vez que un usuario expresa movimientos de sus dedos y manos para simular gestos dinámicos, el paradigma de detección de radar entra en escena
                         para rastrear y reconocer los gestos. Este paradigma de detección de radar incluye hardware, software y algoritmos personalizados. 
                         Suss principios fundamentales de detección se basan en la resolución de movimiento al extraer cambios sutiles en la señal recibida a lo largo del tiempo, 
                         lo que a su vez le permite distinguir movimientos complejos de los dedos y formas deformes de la mano dentro de su campo.
                    </p>
                </div>

            </div>

        </section>
        <section id="importancia">
            <h2>4.- Importancia: más allá de los wereables</h2>
            <div id="importancia1">
                <div id="introduccion">
                    <div id="intro1">
                        <p>
                            Hoy en día, los ordenadores se encuentran en todas partes. 
                            Google ATAP, ha estado pensando en cómo interactuamos con los dispositivos, para darle una vuelta a la interacción 
                            persona ordenador. 
                        </p>
                        <img src="./img/interaccionpersonaordenador.jpeg" alt="interaccion persona ordenador">
                    </div>
                    <div id="Intro2">
                        <P>
                            Gracias a la tecnología del radar Soli y de algortimos avanzados capaces de interpretar los datos recogidos, 
                            se pueden crear dispositivos inteligentes controlados por el movimiento de las manos o de la cabeza
                        </p>
                        <img src="./img/importanciaIntro.jpeg" alt="botón pulsado mediante chip soli">
                    </div>
                    <div>
                        <p>
                            En el proyecto, se han basado en la forma de interactuar de los humanos, intuitivamente, sin decir a veces una simple palabra.
                            Hay determinados gestos que provocan una reacción inmediata, por tanto, ¿Qué pasaría si los ordenadores fueran capaces de entenderlo también?
                        </p>
                        <img src="./img/humanosinteractuando.jpeg" alt="interaccion entre humanos">
                    </div>
                </div>
                <div id="acciones">
                    <h3>Algoritmos</h3>
                    <p>
                        El chip Soli se permite a los dispositivos entender el contexto social que les rodea. 
                        Los algoritmos pueden estimar la orientación de la cabeza del usuario, lo que le permite predecir cómo y cuándo querrá interactuar o prestar atención.
                    </p>
                    <ul>
                        <li><strong>'Aproach and leave'</strong> (acercarse e irse), permite al dispositivo entender cuándo es el momento perfecto para iniciar una conversación
                            por ejemplo: el dispositivo podría notar si alguien se acerca simplemente porque está pasando próximo al objeto, sin intención de interactuar
                            con él, o si se está acercando para llevar a cabo una interacción, como al iniciar una conversación. 
                        </li>
                        <li>
                            <strong>'Turning toward/away'</strong> (acercándose/apartándose), permite puede crear un diálogo más natural entre los usuarios y los dispositivos.
                        </li>
                        <li>
                            <strong>'Glance'</strong> (vistazo), permite al dispositivo entender cuándo un usuario está captando su atención.
                        </li>
                    </ul>
                    <p>
                        Estos dispositivos están diseñados para atendernos desde un segundo plano, de forma tranquila y respetuosa. 
                        Puede tener interacciones que son útiles, pero no molestas, pues la tecnología tiene el contexto suficiente como para reconocer las señales 
                        y ajustarse a las necesidades en el momento.
                    </p>
                    <p>
                        Poco a poco, a medida que estos dispositivos se integran en objetos cotidianos, imaginamos un futuro en el que los productos tengan esta inteligencia social. 
                        La experiencia puede ser increíble, pues se dispondrán de dispositivos que nos entiendan y participen en nuestra vida cotidiana de una forma más considerada, 
                        integrada, cómoda y agradable. 
                    </p>
                </div>
                <div id="ejemploImportancia">
                    <div id="divEj1">
                        <p>
                            Por ejemplo, en estas imágenes se puede observar a una mujer cocinando mientras ve un video de una receta. 
                            Cuando se aleja de la pantalla para lavarse las manos o cortar verduras en otro lugar de la cocina, el vídeo se pone en pausa
                            sin necesidad de que lo pausemos nosotros. 
                        </p>
                        <img id="ejImp1" src="./img/receta1.jpeg" alt="mujer cocinando mientras ve una receta">
                        <img id="ejImp2" src="./img/receta2.jpeg" alt="vídeo pausado sin necesidad de darle al botón de pausa">
                       
                    </div>
                    <p id="pEj1">
                        El dispositivo entiendentiende que ya nos hemos alejado (<strong>'Aproach and leave'</strong>), que no le estamos mirando (<strong>'Turning toward/away'</strong>)
                        y que el usuario ha dejado de prestar atención al vídeo (<strong>'Glance'</strong>).
                    </p>
                </div>
                <div id="conclusion">
                    <p>
                        En definitiva, se describe una nueva forma de interactuar con los dispositivos. Al igual que en su día se inventaron los botones, teclados, mandos a distancia, 
                        o pantallas táctiles. Esta vez, la tecnología, además de permitirnos un medio nuevo de interacción con los ordenadores, gracias a los algoritmos, les permite interpretar 
                        nuestros gestos y acciones para entender el contexto del momento. Lo que hace que los campos de trabajo de utilidad del proyecto Soli sean inmensos. 
                    </p>
                </div>
            </div>
        </section>
        <section id="referencias">
            <h2>Más información sobre chip Soli</h3>
            <div>
                <table>
                    <tr>
                        <th>Título</th>
                        <th>Enlace</th>
                        <th>Tipo de información</th>
                    </tr>
                    <tr>
                        <td>Google ATAP: Project Soli; Usted es la única interfaz que necesita</td>
                        <td class="enlace"><a href="https://atap.google.com/soli/">https://atap.google.com/soli/</a></td>
                        <td>Página oficial de Google ATAP donde se presenta el Proyecto Soli</td>
                    </tr>
                    <tr>
                        <td>Google ATAP: Welcome to Project Soli</td>
                        <td ><a href="https://youtu.be/0QNiZfSsPc0">https://youtu.be/0QNiZfSsPc0</a></td>
                        <td>Vídeo explicativo introductorio sobre el proyecto Soli llevado a cabo por Google ATAP</td>
                    </tr>
                    <tr>
                        <td>Google ATAP: Nonverbal Interactions with Soli Radar</td>
                        <td><a href="https://youtu.be/r-eh2K4HCzI">https://youtu.be/r-eh2K4HCzI</a></td>
                        <td>Vídeo explicativo sobre el Chip Soli, cómo entiende las interacciones no vervales del ser humano</td>
                    </tr>
                    <tr>
                        <td>Google's Project Soli: Controlling devices using hand gestures​ (CNET News)</td>
                        <td><a href="https://youtu.be/Na89OzXllkk">https://youtu.be/Na89OzXllkk</a></td>
                        <td>Vídeo con demostración del uso de Chip Soli en smartWatch y altavoces</td>
                    </tr>
                </table>
            </div>
            
        </section>
    </main>
    <footer>
        <div>
            <p>Trabajo realizado por Paula Isabel Juanes Gil</p>
            <p>Fundamentos de Interacción Persona Ordenador</p>
            <p>Doble Grado en Ingeniería Informática + Administración y Dirección de Empresas Tecnológicas</p>
            <p>Universidad Pontificia de Salamanca</p>
        </div>
        <p>24 de noviembre de 2022</p>
    </footer>
</body>
</html>